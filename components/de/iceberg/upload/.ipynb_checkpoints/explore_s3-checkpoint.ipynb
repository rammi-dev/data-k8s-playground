{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: https://minio-dev.service.dc1.consul:9000\n",
      "Bucket:   dlh-lab\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  \n",
    "\n",
    "S3_ENDPOINT=\"https://minio-dev.service.dc1.consul:9000\"\n",
    "S3_BUCKET = \"dlh-lab\"\n",
    "S3_BUCKET_SOURCE = \"dlh-source-data-lab\"\n",
    "AWS_ACCESS_KEY = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "AWS_SECRET_KEY = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "\n",
    "#print(f\"Acc KEY: {AWS_ACCESS_KEY}\")\n",
    "print(f\"Endpoint: {S3_ENDPOINT}\")\n",
    "print(f\"Bucket:   {S3_BUCKET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "s3fs-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket: dlh-lab\n",
      "\n",
      "  dlh-lab/DEMO\n",
      "  dlh-lab/dane_ow_plan_pracy_jg_4525d1e9-afa5-48a0-936f-26ee1be101be\n",
      "  dlh-lab/default\n",
      "  dlh-lab/gold\n",
      "  dlh-lab/iceberg-rammi\n",
      "  dlh-lab/iceberg_demo\n",
      "  dlh-lab/new_nessie_setup_a2d9707c-3d2f-4fcc-a6d4-70400fda60ff\n",
      "  dlh-lab/normalized\n",
      "  dlh-lab/parquet\n",
      "  dlh-lab/poc\n",
      "  dlh-lab/raw\n",
      "  dlh-lab/semantic\n",
      "  dlh-lab/stor_tab03\n",
      "  dlh-lab/stor_table\n",
      "  dlh-lab/stor_table01\n",
      "  dlh-lab/stor_table02\n",
      "  dlh-lab/stor_table05\n",
      "  dlh-lab/system\n",
      "  dlh-lab/t1\n",
      "  dlh-lab/t5_0e127df0-b752-4f76-b8c7-86354f6171d5\n",
      "  dlh-lab/t6_bde786e4-2be7-43f7-a628-3b0033b1a8d7\n",
      "  dlh-lab/t7_49cb24a1-5a77-4605-aa51-522c72db1534\n",
      "  dlh-lab/t8_46973d81-47dd-44b6-8814-b532f3a7c684\n",
      "  dlh-lab/t9_9e19e1c0-4365-4e00-9ad0-4434612daf16\n",
      "  dlh-lab/tab10_48c867be-466c-47c0-b35e-5dce4d6bab43\n",
      "  dlh-lab/tab11_fdfb1e34-0c76-4f6a-a2c3-9aec16b08372\n",
      "  dlh-lab/tab12_3523601c-42dc-42d0-8fa5-e333bc7b4c65\n",
      "  dlh-lab/tab1_51855741-7768-4c58-a091-df9874f4d3e6\n",
      "  dlh-lab/tab1_5a28d8b6-c551-4d64-95d2-6f84a1e71f4e\n",
      "  dlh-lab/tab2_5a286ae6-8a25-4258-8039-092f1c1ba8a3\n",
      "  dlh-lab/tab_daria_ba46180f-fe16-4c1a-a8c8-d3b3cadd8462\n",
      "  dlh-lab/tabela_test_dl_column\n",
      "  dlh-lab/test_mp\n",
      "  dlh-lab/tmp_jb_1dd99abd-e2b4-40bc-a998-8721d67cf1d9\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "fs = s3fs.S3FileSystem(\n",
    "    endpoint_url=S3_ENDPOINT,\n",
    "    key=AWS_ACCESS_KEY,\n",
    "    secret=AWS_SECRET_KEY,\n",
    "    client_kwargs={\"verify\": False},\n",
    ")\n",
    "\n",
    "# List top-level prefixes in the bucket\n",
    "print(f\"Bucket: {S3_BUCKET}\")\n",
    "print()\n",
    "for item in fs.ls(S3_BUCKET):\n",
    "    print(f\"  {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "s3-list-source",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlh-source-data-lab/reporting\n",
      "  dlh-source-data-lab/reporting/hip\n",
      "dlh-source-data-lab/tmp\n",
      "  dlh-source-data-lab/tmp/PB_PBALL_20250428__20250423000000687.csv.ZIP\n",
      "  dlh-source-data-lab/tmp/PB_TYPPARTNERAPB_20250428__20250423000000689.csv.ZIP\n",
      "  dlh-source-data-lab/tmp/RBUS_ROZLREZEOPER_20250420_S_20250419145110873.csv\n",
      "  dlh-source-data-lab/tmp/chunk.parquet\n",
      "  dlh-source-data-lab/tmp/extract_for_connection_test.csv\n"
     ]
    }
   ],
   "source": [
    "# List source files (csv, zip, parquet)\n",
    "for item in fs.ls(f\"{S3_BUCKET_SOURCE}\"):\n",
    "    print(item)\n",
    "    for sub in fs.ls(item)[:5]:\n",
    "        print(f\"  {sub}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "s3-list-warehouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlh-lab/iceberg-rammi/hip\n",
      "  dlh-lab/iceberg-rammi/hip/\n",
      "  dlh-lab/iceberg-rammi/hip/HISKSE_ROZLMOCYOS\n",
      "  dlh-lab/iceberg-rammi/hip/OMSR_PLANGEN\n",
      "  dlh-lab/iceberg-rammi/hip/PBM_QN\n",
      "  dlh-lab/iceberg-rammi/hip/RBES_ZASGENMAG\n"
     ]
    }
   ],
   "source": [
    "# List warehouse (Iceberg table storage)\n",
    "warehouse_path = f\"{S3_BUCKET}/iceberg-rammi\"\n",
    "if fs.exists(warehouse_path):\n",
    "    for item in fs.ls(warehouse_path):\n",
    "        print(item)\n",
    "        for sub in fs.ls(item)[:5]:\n",
    "            print(f\"  {sub}\")\n",
    "else:\n",
    "    print(\"No warehouse directory yet â€” run spark_ingest.py first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parquet-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "parquet-polars",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9874 parquet files:\n",
      "  s3://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250501__20250501040330309.parquet\n",
      "  s3://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250501__20250502040307971.parquet\n",
      "  s3://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250502__20250502040310839.parquet\n",
      "  s3://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250502__20250503040313880.parquet\n",
      "  s3://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250503__20250503040316747.parquet\n",
      "  s3://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250503__20250504040409839.parquet\n",
      "  s3://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250504__20250504040413116.parquet\n",
      "  s3://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250504__20250505040318762.parquet\n",
      "  s3://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250505__20250505040321602.parquet\n",
      "  s3://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250505__20250506040316635.parquet\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "storage_options = {\n",
    "    \"endpoint_url\": S3_ENDPOINT,\n",
    "    \"aws_access_key_id\": AWS_ACCESS_KEY,\n",
    "    \"aws_secret_access_key\": AWS_SECRET_KEY,\n",
    "    \"aws_region\": \"PSEIDEV\",\n",
    "    \"allow_invalid_certificates\": \"true\",\n",
    "}\n",
    "\n",
    "# Find parquet files in source/parquet/\n",
    "parquet_prefix = f\"{S3_BUCKET}/parquet\"\n",
    "if fs.exists(parquet_prefix):\n",
    "    parquet_files = [f\"s3://{f}\" for f in fs.glob(f\"{parquet_prefix}/**/*.parquet\")]\n",
    "    print(f\"Found {len(parquet_files)} parquet files:\")\n",
    "    for f in parquet_files[:10]:\n",
    "        print(f\"  {f}\")\n",
    "else:\n",
    "    parquet_files = []\n",
    "    print(\"No parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "parquet-read",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s3://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250501__20250501040330309.parquet\n",
      "Rows: 1428, Columns: ['UTC_ZAP', 'UTCTIME', 'MRID_ZAS', 'OW_KOD', 'ZN_BR_NET_KOD', 'ID_PALIWA', 'TYP_AKT', 'TYP_DYSP', 'ZIARNO_CZ', 'DOD_PRZEC', 'DOD_INW', 'UB_REMONT_KAP', 'UBREMSR', 'UBREMBIEZ', 'UBREMAW', 'UBCIEP', 'UBEKSPL', 'UBINWEST', 'SUMUB', 'P_OS', 'UBSIEC', 'OBCIAZ', 'REZIM', 'P_DYSP', 'REZWIR', 'P_DYSP_RUCH', 'RERUCHZIM', 'RERUCHWIR', 'P_INST', 'BO']\n"
     ]
    }
   ],
   "source": [
    "# Read a parquet file with Polars\n",
    "if parquet_files:\n",
    "    df = pl.read_parquet(parquet_files[0], storage_options=storage_options)\n",
    "    print(f\"File: {parquet_files[0]}\")\n",
    "    print(f\"Rows: {len(df)}, Columns: {df.columns}\")\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parquet-read-all",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ALL parquet files, union with schema merge\n",
    "if parquet_files:\n",
    "    dfs = [pl.read_parquet(f, storage_options=storage_options) for f in parquet_files]\n",
    "    combined = pl.concat(dfs, how=\"diagonal\")\n",
    "    print(f\"Combined: {len(combined)} rows, {len(combined.columns)} columns\")\n",
    "    combined.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iceberg-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Iceberg Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spark-session",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "26/02/16 14:38:05 WARN Utils: Your hostname, LNCWA1I05373, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "26/02/16 14:38:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/home/ca743/Work/playground/data-k8s-playground/components/de/iceberg/upload/.venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /home/ca743/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /home/ca743/.ivy2.5.2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-4.0_2.13 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-9066c3d5-4ec7-4b34-b4bb-43cadaa6c84a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.10.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.4.1 in central\n",
      "\tfound software.amazon.awssdk#bundle;2.24.6 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.1.3.Final in central\n",
      ":: resolution report :: resolve 221ms :: artifacts dl 11ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.hadoop#hadoop-aws;3.4.1 from central in [default]\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.10.0 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.1.3.Final from central in [default]\n",
      "\tsoftware.amazon.awssdk#bundle;2.24.6 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   0   |   0   |   0   ||   4   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-9066c3d5-4ec7-4b34-b4bb-43cadaa6c84a\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 4 already retrieved (0kB/8ms)\n",
      "26/02/16 14:38:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark: 4.1.1\n",
      "Warehouse: s3a://dlh-lab/iceberg-rammi\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "ICEBERG_SPARK_JAR = \"org.apache.iceberg:iceberg-spark-runtime-4.0_2.13:1.10.0\"\n",
    "HADOOP_AWS_JAR = \"org.apache.hadoop:hadoop-aws:3.4.1\"\n",
    "\n",
    "warehouse_path = f\"s3a://{S3_BUCKET}/iceberg-rammi\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"iceberg-explorer\")\n",
    "    .master(\"local[2]\")\n",
    "    .config(\"spark.jars.packages\", f\"{ICEBERG_SPARK_JAR},{HADOOP_AWS_JAR}\")\n",
    "    # Iceberg catalog\n",
    "    .config(\"spark.sql.catalog.iceberg_test\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.iceberg_test.type\", \"hadoop\")\n",
    "    .config(\"spark.sql.catalog.iceberg_test.warehouse\", warehouse_path)\n",
    "    # S3 / Hadoop config\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", S3_ENDPOINT)\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", AWS_ACCESS_KEY)\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", AWS_SECRET_KEY)\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"true\")\n",
    "    # Iceberg extensions\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    .config(\"spark.sql.defaultCatalog\", \"iceberg_test\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(f\"Spark: {spark.version}\")\n",
    "print(f\"Warehouse: {warehouse_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "list-namespaces",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|hip      |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List ns\n",
    "spark.sql(\"SHOW NAMESPACES\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "list-tables",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== hip ===\n",
      "+---------+-----------------+-----------+\n",
      "|namespace|tableName        |isTemporary|\n",
      "+---------+-----------------+-----------+\n",
      "|hip      |ZRU_USE          |false      |\n",
      "|hip      |RBES_ZASGENMAG   |false      |\n",
      "|hip      |OMSR_PLANGEN     |false      |\n",
      "|hip      |HISKSE_ROZLMOCYOS|false      |\n",
      "|hip      |PBM_QN           |false      |\n",
      "+---------+-----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List all tables in the default namespace\n",
    "namespaces = [row[0] for row in spark.sql(\"SHOW NAMESPACES\").collect()]\n",
    "for ns in namespaces:\n",
    "    print(f\"\\n=== {ns} ===\")\n",
    "    spark.sql(f\"SHOW TABLES IN {ns}\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "query-table",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: hip.HISKSE_ROZLMOCYOS\n",
      "Rows: 9101352\n",
      "root\n",
      " |-- UTC_ZAP: string (nullable = true)\n",
      " |-- UTCTIME: string (nullable = true)\n",
      " |-- MRID_ZAS: string (nullable = true)\n",
      " |-- OW_KOD: string (nullable = true)\n",
      " |-- ZN_BR_NET_KOD: string (nullable = true)\n",
      " |-- ID_PALIWA: string (nullable = true)\n",
      " |-- TYP_AKT: string (nullable = true)\n",
      " |-- TYP_DYSP: string (nullable = true)\n",
      " |-- ZIARNO_CZ: string (nullable = true)\n",
      " |-- DOD_PRZEC: string (nullable = true)\n",
      " |-- DOD_INW: string (nullable = true)\n",
      " |-- UB_REMONT_KAP: string (nullable = true)\n",
      " |-- UBREMSR: string (nullable = true)\n",
      " |-- UBREMBIEZ: string (nullable = true)\n",
      " |-- UBREMAW: string (nullable = true)\n",
      " |-- UBCIEP: string (nullable = true)\n",
      " |-- UBEKSPL: string (nullable = true)\n",
      " |-- UBINWEST: string (nullable = true)\n",
      " |-- SUMUB: string (nullable = true)\n",
      " |-- P_OS: string (nullable = true)\n",
      " |-- UBSIEC: string (nullable = true)\n",
      " |-- OBCIAZ: string (nullable = true)\n",
      " |-- REZIM: string (nullable = true)\n",
      " |-- P_DYSP: string (nullable = true)\n",
      " |-- REZWIR: string (nullable = true)\n",
      " |-- P_DYSP_RUCH: string (nullable = true)\n",
      " |-- RERUCHZIM: string (nullable = true)\n",
      " |-- RERUCHWIR: string (nullable = true)\n",
      " |-- P_INST: string (nullable = true)\n",
      " |-- BO: string (nullable = true)\n",
      " |-- _source_file: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/16 14:39:14 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 3:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------------------------+------+-------------+---------+-------+--------+---------+---------+-------+-------------+-------+---------+-------+------+-------+--------+------+------+------+------+------+------+------+-----------+---------+---------+------+----+---------------------------------------------------------------------------------------------+\n",
      "|UTC_ZAP            |UTCTIME            |MRID_ZAS                             |OW_KOD|ZN_BR_NET_KOD|ID_PALIWA|TYP_AKT|TYP_DYSP|ZIARNO_CZ|DOD_PRZEC|DOD_INW|UB_REMONT_KAP|UBREMSR|UBREMBIEZ|UBREMAW|UBCIEP|UBEKSPL|UBINWEST|SUMUB |P_OS  |UBSIEC|OBCIAZ|REZIM |P_DYSP|REZWIR|P_DYSP_RUCH|RERUCHZIM|RERUCHWIR|P_INST|BO  |_source_file                                                                                 |\n",
      "+-------------------+-------------------+-------------------------------------+------+-------------+---------+-------+--------+---------+---------+-------+-------------+-------+---------+-------+------+-------+--------+------+------+------+------+------+------+------+-----------+---------+---------+------+----+---------------------------------------------------------------------------------------------+\n",
      "|2025-06-28 06:00:08|2025-06-26 22:00:00|_00716fad-1fbd-4a6c-bf84-e133ade177f9|NULL  |NET          |21       |NULL   |JWCK    |PT15M    |0,000    |0,000  |0,000        |0,000  |0,000    |0,000  |0,000 |0,000  |0,000   |0,000 |48,300|0,000 |0,000 |48,300|48,300|0,000 |48,300     |48,300   |0,000    |NULL  |NULL|s3a://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250627__20250628040442115.parquet|\n",
      "|2025-06-28 06:00:08|2025-06-26 22:00:00|_00716fad-1fbd-4a6c-bf84-e133ade177f9|NULL  |BR           |21       |NULL   |JWCK    |PT15M    |0,000    |0,000  |0,000        |0,000  |0,000    |0,000  |0,000 |0,000  |0,000   |0,000 |50,300|0,000 |0,300 |0,000 |50,300|50,000|50,300     |0,000    |50,000   |NULL  |NULL|s3a://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250627__20250628040442115.parquet|\n",
      "|2025-06-28 06:00:08|2025-06-26 22:00:00|_01094173-37c3-4ee2-9ac7-cdedf6a9b39c|NULL  |BR           |14       |NULL   |JWCK    |PT15M    |0,000    |0,000  |0,000        |0,000  |0,000    |0,000  |0,000 |67,500 |0,000   |67,500|67,500|0,000 |0,000 |0,000 |0,000 |0,000 |0,000      |0,000    |0,000    |NULL  |NULL|s3a://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250627__20250628040442115.parquet|\n",
      "|2025-06-28 06:00:08|2025-06-26 22:00:00|_01094173-37c3-4ee2-9ac7-cdedf6a9b39c|NULL  |NET          |14       |NULL   |JWCK    |PT15M    |0,000    |0,000  |0,000        |0,000  |0,000    |0,000  |0,000 |67,500 |0,000   |67,500|67,500|0,000 |0,000 |0,000 |0,000 |0,000 |0,000      |0,000    |0,000    |NULL  |NULL|s3a://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250627__20250628040442115.parquet|\n",
      "|2025-06-28 06:00:08|2025-06-26 22:00:00|_0123cb3e-2ffa-475d-9f4a-128af1b3bd08|NULL  |NET          |14       |NULL   |Inne    |PT15M    |0,000    |0,000  |0,000        |0,000  |0,000    |0,000  |0,000 |11,900 |0,000   |11,900|20,000|0,000 |8,100 |0,000 |8,100 |0,000 |8,100      |0,000    |0,000    |NULL  |NULL|s3a://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250627__20250628040442115.parquet|\n",
      "|2025-06-28 06:00:08|2025-06-26 22:00:00|_0123cb3e-2ffa-475d-9f4a-128af1b3bd08|NULL  |BR           |14       |NULL   |Inne    |PT15M    |0,000    |0,000  |0,000        |0,000  |0,000    |0,000  |0,000 |11,900 |0,000   |11,900|20,000|0,000 |8,100 |0,000 |8,100 |0,000 |8,100      |0,000    |0,000    |NULL  |NULL|s3a://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250627__20250628040442115.parquet|\n",
      "|2025-06-28 06:00:08|2025-06-26 22:00:00|_0274cb7c-a1b8-488d-a52d-c1e6ad08d9b8|NULL  |BR           |7        |NULL   |JWCK    |PT15M    |0,000    |0,000  |0,000        |0,000  |0,000    |0,000  |0,000 |0,000  |0,000   |0,000 |55,000|0,000 |52,320|0,000 |55,000|2,680 |55,000     |0,000    |2,680    |NULL  |NULL|s3a://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250627__20250628040442115.parquet|\n",
      "|2025-06-28 06:00:08|2025-06-26 22:00:00|_0274cb7c-a1b8-488d-a52d-c1e6ad08d9b8|NULL  |NET          |7        |NULL   |JWCK    |PT15M    |0,000    |0,000  |0,000        |0,000  |0,000    |0,000  |0,000 |0,000  |0,000   |0,000 |50,000|0,000 |47,520|0,000 |50,000|2,480 |50,000     |0,000    |2,480    |NULL  |NULL|s3a://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250627__20250628040442115.parquet|\n",
      "|2025-06-28 06:00:08|2025-06-26 22:00:00|_03ef05a2-b568-466c-a8ec-618c0d37591a|NULL  |BR           |33       |NULL   |JWCK    |PT15M    |0,000    |0,000  |0,000        |0,000  |0,000    |0,000  |0,000 |0,000  |0,000   |0,000 |55,000|0,000 |0,100 |0,000 |55,000|54,900|55,000     |0,000    |54,900   |NULL  |NULL|s3a://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250627__20250628040442115.parquet|\n",
      "|2025-06-28 06:00:08|2025-06-26 22:00:00|_03ef05a2-b568-466c-a8ec-618c0d37591a|NULL  |NET          |33       |NULL   |JWCK    |PT15M    |0,000    |0,000  |0,000        |0,000  |0,000    |0,000  |0,000 |0,000  |0,000   |0,000 |47,000|0,000 |0,000 |47,000|47,000|0,000 |47,000     |47,000   |0,000    |NULL  |NULL|s3a://dlh-lab/parquet/HISKSE_ROZLMOCYOS/HISKSE_ROZLMOCYOS_20250627__20250628040442115.parquet|\n",
      "+-------------------+-------------------+-------------------------------------+------+-------------+---------+-------+--------+---------+---------+-------+-------------+-------+---------+-------+------+-------+--------+------+------+------+------+------+------+------+-----------+---------+---------+------+----+---------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "TABLE = \"hip.HISKSE_ROZLMOCYOS\"\n",
    "\n",
    "df_spark = spark.table(TABLE)\n",
    "print(f\"Table: {TABLE}\")\n",
    "print(f\"Rows: {df_spark.count()}\")\n",
    "df_spark.printSchema()\n",
    "df_spark.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "table-snapshots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+---------+---------+-------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|committed_at           |snapshot_id        |parent_id|operation|manifest_list                                                                                                                  |summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "+-----------------------+-------------------+---------+---------+-------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|2026-02-15 21:25:12.383|3683184752823263966|NULL     |overwrite|s3a://dlh-lab/iceberg-rammi/hip/HISKSE_ROZLMOCYOS/metadata/snap-3683184752823263966-1-32f6de40-e8b0-42a8-9d00-e0fa352852c7.avro|{spark.app.id -> local-1771187030741, added-data-files -> 8, added-records -> 9101352, added-files-size -> 92471921, changed-partition-count -> 1, total-records -> 9101352, total-files-size -> 92471921, total-data-files -> 8, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0, engine-version -> 4.1.1, app-id -> local-1771187030741, engine-name -> spark, iceberg-version -> Apache Iceberg 1.10.0 (commit 2114bf631e49af532d66e2ce148ee49dd1dd1f1f)}|\n",
      "+-----------------------+-------------------+---------+---------+-------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql(f\"SELECT * FROM {TABLE}.snapshots\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "table-files",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------+-----------+------------+------------------+\n",
      "|file_path                                                                                                            |file_format|record_count|file_size_in_bytes|\n",
      "+---------------------------------------------------------------------------------------------------------------------+-----------+------------+------------------+\n",
      "|s3a://dlh-lab/iceberg-rammi/hip/HISKSE_ROZLMOCYOS/data/00000-146-b890bf7d-c18c-457d-adb5-2ef52a69a269-0-00001.parquet|PARQUET    |1989118     |20690275          |\n",
      "|s3a://dlh-lab/iceberg-rammi/hip/HISKSE_ROZLMOCYOS/data/00001-147-b890bf7d-c18c-457d-adb5-2ef52a69a269-0-00001.parquet|PARQUET    |1976690     |20272480          |\n",
      "|s3a://dlh-lab/iceberg-rammi/hip/HISKSE_ROZLMOCYOS/data/00002-148-b890bf7d-c18c-457d-adb5-2ef52a69a269-0-00001.parquet|PARQUET    |1963008     |19856788          |\n",
      "|s3a://dlh-lab/iceberg-rammi/hip/HISKSE_ROZLMOCYOS/data/00003-149-b890bf7d-c18c-457d-adb5-2ef52a69a269-0-00001.parquet|PARQUET    |1961650     |19485626          |\n",
      "|s3a://dlh-lab/iceberg-rammi/hip/HISKSE_ROZLMOCYOS/data/00004-150-b890bf7d-c18c-457d-adb5-2ef52a69a269-0-00001.parquet|PARQUET    |1129004     |10951722          |\n",
      "|s3a://dlh-lab/iceberg-rammi/hip/HISKSE_ROZLMOCYOS/data/00005-151-b890bf7d-c18c-457d-adb5-2ef52a69a269-0-00001.parquet|PARQUET    |28178       |415291            |\n",
      "|s3a://dlh-lab/iceberg-rammi/hip/HISKSE_ROZLMOCYOS/data/00006-152-b890bf7d-c18c-457d-adb5-2ef52a69a269-0-00001.parquet|PARQUET    |27598       |415913            |\n",
      "|s3a://dlh-lab/iceberg-rammi/hip/HISKSE_ROZLMOCYOS/data/00007-153-b890bf7d-c18c-457d-adb5-2ef52a69a269-0-00001.parquet|PARQUET    |26106       |383826            |\n",
      "+---------------------------------------------------------------------------------------------------------------------+-----------+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql(f\"SELECT file_path, file_format, record_count, file_size_in_bytes FROM {TABLE}.files\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "read-parquet-spark",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_s3_path = f\"s3a://{S3_BUCKET}/source/parquet\"\n",
    "\n",
    "df_raw = spark.read.option(\"mergeSchema\", \"true\").parquet(f\"{parquet_s3_path}/*/*\")\n",
    "print(f\"Raw parquet rows: {df_raw.count()}\")\n",
    "df_raw.printSchema()\n",
    "df_raw.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "custom-sql",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|cnt    |\n",
      "+-------+\n",
      "|9101352|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT count(*) as cnt\n",
    "    FROM hip.HISKSE_ROZLMOCYOS\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "print(\"Spark stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
