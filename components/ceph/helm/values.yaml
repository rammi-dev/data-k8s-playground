# Rook-Ceph Playground Values
# Configures both operator and cluster via Helm dependencies
#
# Deploy with:
#   helm dependency update
#   helm upgrade --install rook-ceph . -n rook-ceph --create-namespace

# ============================================
# Operator Chart Configuration (alias: operator)
# See: https://github.com/rook/rook/blob/master/deploy/charts/rook-ceph/values.yaml
# ============================================
operator:
  enabled: true

  # Resource limits for development environment
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 128Mi

  # Enable discovery daemon for device detection
  enableDiscoveryDaemon: true

  # CSI driver settings
  csi:
    enableRbdDriver: true
    enableCephfsDriver: true

    # Resource limits for CSI pods
    csiRBDProvisionerResource: |
      - name: csi-provisioner
        resource:
          requests:
            memory: 64Mi
            cpu: 50m
          limits:
            memory: 256Mi
            cpu: 200m

    csiCephFSProvisionerResource: |
      - name: csi-provisioner
        resource:
          requests:
            memory: 64Mi
            cpu: 50m
          limits:
            memory: 256Mi
            cpu: 200m

  # Monitoring - disable for dev
  monitoring:
    enabled: false

# ============================================
# Cluster Chart Configuration (alias: cluster)
# See: https://github.com/rook/rook/blob/master/deploy/charts/rook-ceph-cluster/values.yaml
# ============================================
cluster:
  enabled: true

  # Operator namespace (must match where operator is installed)
  operatorNamespace: rook-ceph

  # Ceph image (v1.19+ moved this out of cephClusterSpec)
  cephImage:
    repository: quay.io/ceph/ceph
    tag: v20
    allowUnsupported: true

  # Ceph cluster configuration
  cephClusterSpec:
    dataDirHostPath: /var/lib/rook
    skipUpgradeChecks: true

    mon:
      count: 1
      allowMultiplePerNode: true

    mgr:
      count: 1
      allowMultiplePerNode: true
      modules:
        - name: rook
          enabled: true
        - name: pg_autoscaler
          enabled: true

    dashboard:
      enabled: true
      ssl: false

    # Device-based storage - uses extra VHDs attached to each Hyper-V node
    storage:
      useAllNodes: true
      useAllDevices: true
      allowDeviceClassUpdate: true
      allowOsdCrushWeightUpdate: false

    monitoring:
      enabled: false

    resources:
      mon:
        limits:
          memory: "1Gi"
        requests:
          cpu: "100m"
          memory: "512Mi"
      osd:
        limits:
          memory: "2Gi"
        requests:
          cpu: "100m"
          memory: "1Gi"
      mgr:
        limits:
          memory: "1Gi"
        requests:
          cpu: "100m"
          memory: "512Mi"

    crashCollector:
      disable: true

    priorityClassNames:
      all: system-node-critical
      mgr: system-cluster-critical

    disruptionManagement:
      managePodBudgets: true

    cephConfig:
      global:
        osd_pool_default_size: "1"
        mon_warn_on_pool_no_redundancy: "false"
        bdev_flock_retry: "20"
        bluefs_buffered_io: "false"
        mon_data_avail_warn: "10"

    placement:
      all:
        tolerations:
          - operator: Exists

  # Builtin manager pool (must be size 1 to match default pool size)
  cephBlockPools:
    - name: builtin-mgr
      spec:
        name: .mgr
        replicated:
          size: 1
          requireSafeReplicaSize: false
      storageClass:
        enabled: false
    - name: replicapool
      spec:
        replicated:
          size: 1
          requireSafeReplicaSize: false
      storageClass:
        enabled: true
        name: ceph-block
        isDefault: true
        reclaimPolicy: Delete
        allowVolumeExpansion: true
        parameters:
          imageFormat: "2"
          imageFeatures: layering

  # Object Store (S3 gateway)
  cephObjectStores:
    - name: s3-store
      spec:
        metadataPool:
          replicated:
            size: 1
        dataPool:
          replicated:
            size: 1
        preservePoolsOnDelete: false
        gateway:
          port: 80
          instances: 1
          resources:
            limits:
              cpu: "2"
              memory: "2Gi"
            requests:
              cpu: "100m"
              memory: "1Gi"
      storageClass:
        enabled: true
        name: ceph-bucket
        reclaimPolicy: Delete

  # Toolbox for debugging
  toolbox:
    enabled: true
